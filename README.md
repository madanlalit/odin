# Odin ðŸ”±

AI-powered computer automation agent using vision LLMs.

## Architecture

```mermaid
graph TD
    A[Screen Capture] --> B[Image Processing]
    B --> C[LLM Vision Model]
    C --> D[Action Parser]
    D --> E[Safety Check]
    E --> F[Action Controller]
    F --> G{Task Complete?}
    G -->|No| A
    G -->|Yes| H[Return Result]
```

## Features

- **ReAct Loop**: Reason + Act pattern for intelligent automation
- **Vision LLM**: Uses OpenRouter to access GPT-4V, Claude 3, Gemini, etc.
- **PyAutoGUI Actions**: Click, type, scroll, hotkeys, and more
- **Safety Layer**: Rate limiting, bounds checking, dangerous action detection
- **Memory**: Tracks conversation history and executed actions

## Installation

```bash
# Clone the repo
git clone https://github.com/your-username/odin.git
cd odin

# Install with uv
uv sync
```

## Setup

1. Get an API key from [OpenRouter](https://openrouter.ai/)
2. Set the environment variable:

```bash
export OPENROUTER_API_KEY="your-api-key"
```

3. Grant permissions (macOS):
   - **Screen Recording**: System Settings â†’ Privacy & Security â†’ Screen Recording
   - **Accessibility**: System Settings â†’ Privacy & Security â†’ Accessibility

## Usage

```python
from odin import Agent, create_client

# Create LLM client
llm = create_client(model="google/gemini-2.0-flash-001")

# Create agent
agent = Agent(llm)

# Run a task
result = agent.run("Open Safari and search for 'weather today'")

print(f"Success: {result.success}")
print(f"Message: {result.message}")
print(f"Steps: {result.total_steps}")
```

## Configuration

```python
from odin import Agent, AgentConfig
from odin.action.safety import SafetyConfig

config = AgentConfig(
    max_steps=50,           # Max steps before stopping
    step_delay=0.5,         # Delay between steps
    use_grid=True,          # Overlay grid on screenshots
    grid_step=100,          # Grid cell size in pixels
    safety=SafetyConfig(
        max_actions_per_minute=60,
        min_action_delay=0.1,
    ),
)

agent = Agent(llm, config=config)
```

## Project Structure

```
src/odin/
â”œâ”€â”€ agent/           # ReAct loop agent
â”‚   â”œâ”€â”€ core.py      # Main agent class
â”‚   â”œâ”€â”€ memory.py    # Conversation/action history
â”‚   â””â”€â”€ parser.py    # LLM response parser
â”œâ”€â”€ action/          # GUI automation
â”‚   â”œâ”€â”€ controller.py # PyAutoGUI actions
â”‚   â””â”€â”€ safety.py    # Safety checks
â”œâ”€â”€ llm/             # LLM integration
â”‚   â”œâ”€â”€ client.py    # OpenRouter client
â”‚   â””â”€â”€ prompts.py   # System prompts
â””â”€â”€ perception/      # Screen capture
    â”œâ”€â”€ screen.py    # Screenshot capture
    â””â”€â”€ processing.py # Image processing
```

## License

MIT
